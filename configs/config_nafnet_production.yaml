training:
  epochs: 200
  batch_size: 8 
  learning_rate: 0.001 
  optimizer: "Adam" # Options: Adam, AdamW
  scheduler: "CosineAnnealing" # Options: CosineAnnealing, StepLR
  save_interval: 50
  seed: 42
  gpu_id: 0
  num_workers: 8 

losses:
  weights:
    l1: 1.0
    ssim: 0.0
    psnr: 0.0
    charbonnier: 0.0
    vgg: 0.0
    sure: 0.0
  auxiliary:
    charbonnier_eps: 0.001 # Standard epsilon
